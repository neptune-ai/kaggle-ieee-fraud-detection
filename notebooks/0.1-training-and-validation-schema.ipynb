{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading features\n\nI am using the features from @artgors [EDA and models kernel](https://www.kaggle.com/artgor/eda-and-models)."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_features_path = '../input/baseline-features/train_features.csv'\ntest_features_path = '../input/baseline-features/test_features.csv'\n\ntrain = pd.read_csv(train_features_path)\ntest = pd.read_csv(test_features_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.sort_values('TransactionDT')\ntest = test.sort_values('TransactionDT')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's plot train and test by 'TransactionDT'."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(1,2, figsize=(16,4))\ntrain.groupby(['TransactionDT'])['TransactionDT'].size().plot(ax=axs[0])\ntest.groupby(['TransactionDT'])['TransactionDT'].size().plot(ax=axs[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can clearly see the time split."},{"metadata":{"trusted":true},"cell_type":"code","source":"del test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Finding a good time split\nSo let's try to decide what should be the proper time split."},{"metadata":{"trusted":true},"cell_type":"code","source":"split_perc = [p*0.01 for p in range(100)]\ny_means_train, y_means_valid = [],[]\nfor p in split_perc:\n    idx = int(p*len(train))\n    y_means_train.append(train['isFraud'][:idx].mean())\n    y_means_valid.append(train['isFraud'][idx:].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16,4))\nax.plot(split_perc, y_means_train, label='train')\nax.plot(split_perc, y_means_valid, label='valid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split_perc_df = pd.DataFrame({'perc':split_perc,'train':y_means_train, 'valid':y_means_valid})\nsplit_perc_df['diff'] = abs(split_perc_df['train']-split_perc_df['valid'])\nsplit_perc_df.sort_values('diff').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okey, it seems that seems that we have a few candidates that have similiar `isFraud` fraction.\nLet's now see what is the difference row-wise in those `0.74` and `0.87` splits."},{"metadata":{"trusted":true},"cell_type":"code","source":"0.13*len(train), 0.26*len(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, it's quite large and the difference in `isFraud` fraction is not, so I will go with the `0.26` of train as my validation set.\n\n# Finding a good train sample\n\nIn imbalanced problems a lot of the times negative samples do not bringing that much to the table from a certain point.\nI want to explore whether I can subsample negative samples from the train (keeping valid as is) and get a similar score on valid.\nBy doing that I can cut down the training time significantly and experiment faster as a result.\n\nLet's implement a simple sampling function:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sample_negative_class(train, perc):\n    train_pos = train[train.isFraud==1]\n    train_neg = train[train.isFraud==0].sample(frac=perc)\n    \n    train = pd.concat([train_pos, train_neg], axis=0)\n    train = train.sort_values('TransactionDT')\n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_predict(train, valid, model_params, training_params):\n    X_train = train.drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\n    y_train = train['isFraud']\n\n    X_valid = valid.drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\n    y_valid = valid['isFraud']\n    \n    trn_data = lgb.Dataset(X_train, y_train)\n    val_data = lgb.Dataset(X_valid, y_valid)\n\n    clf = lgb.train(model_params, trn_data, \n                    training_params['num_boosting_rounds'], \n                    valid_sets = [trn_data, val_data], \n                    early_stopping_rounds = training_params['early_stopping_rounds'],\n                    verbose_eval=False\n                   )\n    train_preds = clf.predict(X_train, num_iteration=clf.best_iteration)\n    valid_preds = clf.predict(X_valid, num_iteration=clf.best_iteration)\n    return train_preds, valid_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_split = int(0.74*len(train))\ntrain_split, valid_split = train[:idx_split], train[idx_split:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_params = {'num_leaves': 256,\n                  'min_child_samples': 79,\n                  'objective': 'binary',\n                  'max_depth': 15,\n                  'learning_rate': 0.05,\n                  \"boosting_type\": \"gbdt\",\n                  \"subsample_freq\": 3,\n                  \"subsample\": 0.9,\n                  \"bagging_seed\": 11,\n                  \"metric\": 'auc',\n                  \"verbosity\": -1,\n                  'reg_alpha': 0.3,\n                  'reg_lambda': 0.3,\n                  'colsample_bytree': 0.9\n                 }\n\ntraining_params = {'num_boosting_rounds':1000,\n                   'early_stopping_rounds':100,\n               }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can go ahead and train on 20 different sample options."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sample_perc = [p*0.05 for p in range(1,20,1)]\ntrain_scores, valid_scores = [],[]\nfor perc in train_sample_perc:\n    print('processing for perc {}'.format(perc))\n    train_sample = sample_negative_class(train_split, perc)\n    train_preds, valid_preds = fit_predict(train_sample, valid_split, model_params, training_params)\n    \n    train_score = roc_auc_score(train_sample['isFraud'], train_preds)\n    valid_score = roc_auc_score(valid_split['isFraud'], valid_preds)\n    print(perc, train_score, valid_score)\n    train_scores.append(train_score)\n    valid_scores.append(valid_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(2,1, figsize=(16,4))\naxs[0].plot(train_sample_perc, train_scores, label='train')\naxs[1].plot(train_sample_perc, valid_scores, label='valid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_perc_df = pd.DataFrame({'perc':train_sample_perc,'train':train_scores, 'valid':valid_scores})\nsample_perc_df.sort_values('valid', ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, so we can see that the difference in scores from `0.1` to `1.0` of the negative samples is only `0.002`.\nWhat is interesting is that for those larger samples like `0.75` we get a bump which suggest a lot of noise here. \nThis is more of the reason (in my opinion) to experiment with a smaller sample of negatives and from time to time check it\non the entire dataset.\n\nWhat do you think?\n\n**Note**\n\nI will be adding this to the project that I discuss [here](https://www.kaggle.com/c/ieee-fraud-detection/discussion/100311#latest-578849)."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}